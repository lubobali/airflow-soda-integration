Airflow + Soda Integration Demo

This project demonstrates how to integrate Soda data quality checks into an Apache Airflow DAG pipeline, using Postgres as the sample data source.

ğŸ”§ Tools Used

Apache Airflow (via Docker Compose)

Soda CLI for data quality checks

Postgres (sample data source)

ğŸš€ Current Status

âœ… Fully working Airflow DAG that runs a Soda scan on a dataset
âœ… Docker-based setup for local development and testing
âœ… Automated data quality validation as part of the Airflow pipeline

ğŸ“ Project Structure

bash
Copy
Edit
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ soda_scan_dag.py           # Airflow DAG to run Soda scan
â”œâ”€â”€ soda/
â”‚   â”œâ”€â”€ config.yml                 # Soda CLI configuration
â”‚   â”œâ”€â”€ scan_checks.yml           # Data quality checks
â”‚   â””â”€â”€ README.md                 # Soda setup description (optional)
â”œâ”€â”€ docker-compose.yml            # Docker Compose setup for Airflow + Postgres
â””â”€â”€ README.md                     # Project overview and setup instructions
âš™ï¸ Setup Instructions
Clone the repo

bash
Copy
Edit
git clone https://github.com/lubobali/airflow-soda-integration.git
cd airflow-soda-integration
Start the Airflow + Postgres stack

bash
Copy
Edit
docker compose up -d
Access Airflow UI
Open your browser and go to:
http://localhost:8090

ğŸ§ª Run the Soda Scan DAG

In the Airflow UI, find the DAG named soda_scan_example

Trigger it manually or wait for the scheduled run

Monitor the task logs to view Soda scan output

âœ… What Happens Behind the Scenes

The DAG uses a BashOperator to execute a Soda CLI command

Soda connects to the Postgres database defined in config.yml

Soda runs data quality checks from scan_checks.yml

Results are shown directly in the Airflow task logs

ğŸ“– Notes
Postgres runs with default credentials (airflow/airflow)

You can update config.yml if your database changes

Add more checks to scan_checks.yml as needed

ğŸ§  Requirements

Docker installed locally

No other dependencies â€” everything runs inside containers
