Airflow + Soda Integration Demo
This project demonstrates how to integrate Soda data quality checks into an Apache Airflow DAG pipeline, using Postgres as the sample data source.

ğŸ”§ Tools Used
Apache Airflow (via Docker Compose)

Soda CLI for data quality checks

Postgres (sample data source)

ğŸš€ Current Status
Fully working DAG that runs a Soda scan on a dataset

Docker-based setup for local development and testing

Automated data quality validation as part of the Airflow pipeline

ğŸ“ Project Structure
bash
Copy
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ soda_scan_dag.py            # Airflow DAG to run Soda scan
â”œâ”€â”€ soda/
â”‚   â”œâ”€â”€ config.yml                  # Soda CLI configuration
â”‚   â”œâ”€â”€ scan_checks.yml             # Data quality checks definitions
â”‚   â””â”€â”€ README.md                   # Soda setup description
â”œâ”€â”€ docker-compose.yml              # Docker Compose setup for Airflow + Postgres
â””â”€â”€ README.md                      # Project description and instructions
âš™ï¸ Setup Instructions
Clone the repo
bash
Copy
git clone https://github.com/lubobali/airflow-soda-integration.git
cd airflow-soda-integration
Start the Airflow + Postgres stack
bash
Copy
docker compose up -d
Access the Airflow Web UI
Open your browser and go to:

arduino
Copy
http://localhost:8090
Run the Soda data quality scan DAG
Find the DAG named soda_scan_example in the Airflow UI.

Trigger it manually or wait for the scheduled run.

Monitor the task logs to see the Soda scan results.

âœ… What Happens
The DAG runs a BashOperator task that executes the Soda CLI command.

Soda connects to the Postgres database.

Data quality checks defined in scan_checks.yml are executed.

Results are visible in Airflow task logs.

ğŸ“– Notes
Postgres runs with default credentials set in soda/config.yml.

Update the config if your database setup changes.

Extend scan_checks.yml to add more data quality rules as needed.
